# GitHub Issue #40 æ€§èƒ½æ”¹è¿›å®ç°æŒ‡å—

## ğŸ“‹ æ”¹è¿›æ¦‚è¿°

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•ä½¿ç”¨æ”¹è¿›ç‰ˆçš„ EEG-Conformer æ¨¡å‹ (åŸºäº GitHub Issue #40)

**æ”¹è¿›å†…å®¹**:
1. âœ… **ç®€åŒ–å…¨è¿æ¥å±‚**: ä» 3 å±‚ (2440â†’256â†’32â†’4) ç®€åŒ–ä¸º 1 å±‚ (2440â†’4)
2. âœ… **Pre-Norm æ¶æ„**: LayerNorm åœ¨ MultiHeadAttention ä¹‹å‰ (åŸä»£ç å·²æ­£ç¡®)
3. âœ… **å¢åŠ æ•°æ®å¢å¼ºé¢‘ç‡**: ä» 1x å¢åŠ åˆ° 3x
4. âœ… **æ·»åŠ éªŒè¯é›†**: ä»è®­ç»ƒé›†åˆ†å‡º 20% ä½œä¸ºéªŒè¯é›†ï¼ŒåŸºäºéªŒè¯é›†å‡†ç¡®ç‡ä¿å­˜æœ€ä½³æ¨¡å‹

**é¢„æœŸæå‡**: +5-10% å‡†ç¡®ç‡

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³• 1: è®­ç»ƒå•ä¸ª Subject (å¿«é€Ÿæµ‹è¯•)

```bash
# åœ¨ PC ä¸Šæ¿€æ´»ç¯å¢ƒ
conda activate eeg-moabb

# è®­ç»ƒ Subject 1 (ç”¨äºå¿«é€Ÿæµ‹è¯•)
python save_best_models_improved.py --subjects 1 --save_dir ./models_improved

# è®­ç»ƒ Subject 3 (å·²çŸ¥æœ€ä½³æ€§èƒ½)
python save_best_models_improved.py --subjects 3 --save_dir ./models_improved
```

### æ–¹æ³• 2: è®­ç»ƒæ‰€æœ‰ Subjects (å®Œæ•´å¯¹æ¯”)

```bash
# è®­ç»ƒæ‰€æœ‰ 9 ä¸ª subjects
python save_best_models_improved.py --subjects all --save_dir ./models_improved

# æˆ–è€…æŒ‡å®šç‰¹å®šçš„ subjects
python save_best_models_improved.py --subjects 1,3,7,8 --save_dir ./models_improved
```

### æ–¹æ³• 3: ä½¿ç”¨ conformer_improved.py (å¦‚æœæƒ³ä¿®æ”¹ä»£ç )

```bash
# ç›´æ¥è¿è¡Œæ”¹è¿›ç‰ˆè®­ç»ƒè„šæœ¬
python conformer_improved.py
```

---

## ğŸ“‚ æ–‡ä»¶è¯´æ˜

### æ–°åˆ›å»ºçš„æ–‡ä»¶

1. **conformer_improved.py**
   - æ”¹è¿›ç‰ˆçš„å®Œæ•´è®­ç»ƒè„šæœ¬
   - åŒ…å«æ‰€æœ‰ 4 ä¸ªæ”¹è¿›
   - å¯ä»¥ç›´æ¥è¿è¡Œ `python conformer_improved.py`

2. **save_best_models_improved.py**
   - æ”¹è¿›ç‰ˆçš„æ¨¡å‹ä¿å­˜è„šæœ¬ (æ¨èä½¿ç”¨)
   - æ”¯æŒå‘½ä»¤è¡Œå‚æ•°
   - è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹å’Œç»Ÿè®¡ä¿¡æ¯
   - æ›´çµæ´»ï¼Œå¯ä»¥æŒ‡å®šè®­ç»ƒå“ªäº› subjects

---

## ğŸ”§ å‘½ä»¤è¡Œå‚æ•°

### save_best_models_improved.py å‚æ•°

```bash
python save_best_models_improved.py \
  --subjects all \              # è®­ç»ƒå“ªäº› subjects: "all" æˆ– "1,3,5"
  --save_dir ./models_improved \  # æ¨¡å‹ä¿å­˜ç›®å½•
  --validate_ratio 0.2 \        # éªŒè¯é›†æ¯”ä¾‹ (é»˜è®¤ 20%)
  --seed 42                     # éšæœºç§å­ (å¯é€‰ï¼Œé»˜è®¤éšæœº)
```

**å‚æ•°è¯´æ˜**:
- `--subjects`: è¦è®­ç»ƒçš„ subjects
  - `all`: è®­ç»ƒæ‰€æœ‰ 9 ä¸ª subjects (1-9)
  - `1,3,5`: åªè®­ç»ƒ Subject 1, 3, 5
  - `1`: åªè®­ç»ƒ Subject 1

- `--save_dir`: æ¨¡å‹ä¿å­˜ç›®å½•
  - é»˜è®¤: `./models_improved`
  - ä¼šè‡ªåŠ¨åˆ›å»ºç›®å½•

- `--validate_ratio`: éªŒè¯é›†æ¯”ä¾‹
  - é»˜è®¤: 0.2 (20% çš„è®­ç»ƒæ•°æ®ç”¨ä½œéªŒè¯é›†)
  - å¯é€‰: 0.1-0.3

- `--seed`: éšæœºç§å­
  - é»˜è®¤: éšæœº
  - æŒ‡å®šç§å­å¯ä»¥é‡ç°ç»“æœ

---

## ğŸ“Š è¾“å‡ºæ–‡ä»¶

è®­ç»ƒå®Œæˆåï¼Œä¼šåœ¨ `./models_improved/` ç›®å½•ä¸‹ç”Ÿæˆï¼š

```
./models_improved/
â”œâ”€â”€ subject_1_best.pth          # Subject 1 æœ€ä½³æ¨¡å‹
â”œâ”€â”€ subject_1_stats.json        # Subject 1 ç»Ÿè®¡ä¿¡æ¯
â”œâ”€â”€ log_subject1.txt            # Subject 1 è®­ç»ƒæ—¥å¿—
â”œâ”€â”€ subject_2_best.pth
â”œâ”€â”€ subject_2_stats.json
â”œâ”€â”€ log_subject2.txt
â”œâ”€â”€ ...
â””â”€â”€ training_summary.txt        # æ€»ä½“è®­ç»ƒæ‘˜è¦
```

### æ¨¡å‹æ–‡ä»¶å†…å®¹ (.pth)

```python
{
    'epoch': æœ€ä½³ epoch,
    'model_state_dict': æ¨¡å‹å‚æ•°,
    'optimizer_state_dict': ä¼˜åŒ–å™¨å‚æ•°,
    'best_val_acc': æœ€ä½³éªŒè¯é›†å‡†ç¡®ç‡,
    'best_test_acc': å¯¹åº”çš„æµ‹è¯•é›†å‡†ç¡®ç‡,
    'normalization_params': {
        'mean': æ ‡å‡†åŒ–å‡å€¼,
        'std': æ ‡å‡†åŒ–æ ‡å‡†å·®
    }
}
```

### ç»Ÿè®¡æ–‡ä»¶å†…å®¹ (.json)

```json
{
    "subject": 1,
    "best_val_accuracy": 0.85,
    "best_test_accuracy": 0.87,
    "average_test_accuracy": 0.78,
    "best_epoch": 1234,
    "total_epochs": 2000,
    "validate_ratio": 0.2,
    "number_augmentation": 3,
    "normalization_params": {
        "mean": 0.0,
        "std": 1.0
    },
    "improvements": {
        "1_simplified_fc": "Single layer FC (2440->4)",
        "2_pre_norm": "LayerNorm before MHA (already correct)",
        "3_data_aug": "Augmentation 3x",
        "4_validation_set": "20.0% of training data"
    }
}
```

---

## ğŸ¯ æ¨èè®­ç»ƒç­–ç•¥

### ç­–ç•¥ 1: å¿«é€ŸéªŒè¯ (æ¨èå…ˆåš)

```bash
# åªè®­ç»ƒ Subject 3 (å·²çŸ¥æœ€ä½³æ€§èƒ½ 95.14%)
python save_best_models_improved.py --subjects 3 --save_dir ./models_improved --seed 42

# é¢„è®¡æ—¶é—´: çº¦ 2-4 å°æ—¶ (å–å†³äº GPU)
# é¢„æœŸç»“æœ: 96-98% å‡†ç¡®ç‡ (æ¯”åŸºçº¿æå‡ 1-3%)
```

### ç­–ç•¥ 2: å¯¹æ¯”æµ‹è¯•

```bash
# å…ˆè®­ç»ƒå‡ ä¸ªä»£è¡¨æ€§çš„ subjects
python save_best_models_improved.py --subjects 1,3,7,8 --save_dir ./models_improved

# å¯¹æ¯”åŸºçº¿æ¨¡å‹ (./models/subject_3_best.pth) å’Œæ”¹è¿›æ¨¡å‹ (./models_improved/subject_3_best.pth)
```

### ç­–ç•¥ 3: å®Œæ•´è®­ç»ƒ

```bash
# è®­ç»ƒæ‰€æœ‰ 9 ä¸ª subjects
python save_best_models_improved.py --subjects all --save_dir ./models_improved

# é¢„è®¡æ—¶é—´: çº¦ 18-36 å°æ—¶ (å–å†³äº GPU)
# é¢„æœŸç»“æœ: å¹³å‡å‡†ç¡®ç‡ä» 79.13% æå‡åˆ° 84-87%
```

---

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

### åŸºçº¿æ¨¡å‹ (åŸç‰ˆ)

| Subject | å‡†ç¡®ç‡ | é…ç½® |
|---------|--------|------|
| Subject 1 | 86.1% | 3å±‚FC, 1xå¢å¼º, æ— éªŒè¯é›† |
| Subject 2 | 54.5% | (BCIæ–‡ç›²) |
| Subject 3 | **95.14%** | |
| Subject 4 | 74.3% | |
| Subject 5 | 78.8% | |
| Subject 6 | 63.2% | |
| Subject 7 | 89.2% | |
| Subject 8 | 88.9% | |
| Subject 9 | 82.6% | |
| **å¹³å‡** | **79.13%** | |

### æ”¹è¿›æ¨¡å‹ (Issue #40)

| Subject | é¢„æœŸå‡†ç¡®ç‡ | æ”¹è¿›é…ç½® |
|---------|-----------|---------|
| Subject 1 | ~90% | 1å±‚FC, 3xå¢å¼º, 20%éªŒè¯é›† |
| Subject 2 | ~55-60% | (BCIæ–‡ç›²ä»ä¼šå­˜åœ¨) |
| Subject 3 | **~97%** | |
| Subject 4 | ~79% | |
| Subject 5 | ~83% | |
| Subject 6 | ~68% | |
| Subject 7 | ~92% | |
| Subject 8 | ~92% | |
| Subject 9 | ~87% | |
| **å¹³å‡** | **~84-87%** | **+5-8% æå‡** |

---

## ğŸ” å…³é”®æ”¹è¿›è¯¦è§£

### æ”¹è¿› 1: ç®€åŒ–å…¨è¿æ¥å±‚

**ä½ç½®**: `conformer_improved.py` ç¬¬ 194-199 è¡Œ

```python
# åŸç‰ˆ (3å±‚)
self.fc = nn.Sequential(
    nn.Linear(2440, 256),
    nn.ELU(),
    nn.Dropout(0.5),
    nn.Linear(256, 32),
    nn.ELU(),
    nn.Dropout(0.3),
    nn.Linear(32, 4)
)

# æ”¹è¿›ç‰ˆ (1å±‚)
self.fc = nn.Sequential(
    nn.Dropout(0.5),
    nn.Linear(2440, 4)  # ç›´æ¥æ˜ å°„!
)
```

**åŸç†**:
- æµ…å±‚ ConvNet æå–çš„ç‰¹å¾å·²ç»è¶³å¤Ÿå¥½
- å¤šå±‚ FC å¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆ
- å•å±‚ FC æä¾›æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›

**é¢„æœŸæå‡**: +2-3%

---

### æ”¹è¿› 2: Pre-Norm æ¶æ„

**ä½ç½®**: `conformer_improved.py` ç¬¬ 167-176 è¡Œ

```python
# æ­£ç¡®çš„é¡ºåº (åŸä»£ç å·²ç»æ˜¯è¿™æ ·)
ResidualAdd(nn.Sequential(
    nn.LayerNorm(emb_size),       # âœ“ LayerNorm åœ¨å‰
    MultiHeadAttention(...),      # âœ“ Attention åœ¨å
    nn.Dropout(drop_p)
))
```

**åŸç†**:
- LayerNorm åœ¨ MHA ä¹‹å‰å¯ä»¥ç¨³å®šæ¢¯åº¦
- æ”¹å–„è®­ç»ƒç¨³å®šæ€§
- æé«˜æ”¶æ•›é€Ÿåº¦

**çŠ¶æ€**: åŸä»£ç å·²æ­£ç¡®ï¼Œæ— éœ€ä¿®æ”¹

---

### æ”¹è¿› 3: å¢åŠ æ•°æ®å¢å¼ºé¢‘ç‡

**ä½ç½®**: `save_best_models_improved.py` ç¬¬ 234 è¡Œ, ç¬¬ 417-420 è¡Œ

```python
# è®¾ç½®å¢å¼ºæ¬¡æ•°
self.number_augmentation = 3  # 3x instead of 1x

# åœ¨è®­ç»ƒå¾ªç¯ä¸­
for aug_idx in range(self.number_augmentation):
    aug_data, aug_label = self.interaug(self.allData, self.allLabel)
    img_batch = torch.cat((img_batch, aug_data))
    label_batch = torch.cat((label_batch, aug_label))
```

**åŸç†**:
- æ›´å¤šçš„å¢å¼ºæ•°æ®æä¾›æ›´å¥½çš„æ³›åŒ–
- å‡å°‘è¿‡æ‹Ÿåˆ
- å¢åŠ è®­ç»ƒæ ·æœ¬å¤šæ ·æ€§

**é¢„æœŸæå‡**: +3-5%

---

### æ”¹è¿› 4: æ·»åŠ éªŒè¯é›†

**ä½ç½®**: `save_best_models_improved.py` ç¬¬ 303-319 è¡Œ

```python
# åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
num_samples = len(self.allData)
num_validate = int(self.validate_ratio * num_samples)  # 20%
num_train = num_samples - num_validate

self.trainData = self.allData[:num_train]
self.trainLabel = self.allLabel[:num_train]
self.valData = self.allData[num_train:]
self.valLabel = self.allLabel[num_train:]

# åŸºäºéªŒè¯é›†å‡†ç¡®ç‡ä¿å­˜æœ€ä½³æ¨¡å‹
if val_acc > bestValAcc:
    bestValAcc = val_acc
    bestAcc = test_acc  # å¯¹åº”çš„æµ‹è¯•é›†å‡†ç¡®ç‡
    # ä¿å­˜æ¨¡å‹...
```

**åŸç†**:
- é¿å…åŸºäºæµ‹è¯•é›†é€‰æ‹©æ¨¡å‹ (æ•°æ®æ³„æ¼)
- æ›´çœŸå®çš„æ€§èƒ½è¯„ä¼°
- é˜²æ­¢è¿‡æ‹Ÿåˆæµ‹è¯•é›†

**å¥½å¤„**: æ›´å¯é çš„æ¨¡å‹é€‰æ‹©

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. è®­ç»ƒæ—¶é—´

- **å•ä¸ª Subject**: 2-4 å°æ—¶ (2000 epochs)
- **æ‰€æœ‰ 9 ä¸ª Subjects**: 18-36 å°æ—¶
- **GPU è¦æ±‚**: RTX 5080 (ä½ æœ‰)

### 2. BCI æ–‡ç›²ç°è±¡

- Subject 2 çš„ä½å‡†ç¡®ç‡ (~54%) æ˜¯**æ­£å¸¸ç°è±¡**
- æ”¹è¿›åå¯èƒ½æå‡åˆ° 55-60%ï¼Œä½†ä¸ä¼šæœ‰å·¨å¤§æå‡
- è¿™æ˜¯ç§‘å­¦ç•Œå…¬è®¤çš„ç°è±¡ï¼Œä¸æ˜¯ç®—æ³•é—®é¢˜

### 3. å†…å­˜å ç”¨

- ç”±äºå¢åŠ äº† 3x æ•°æ®å¢å¼ºï¼Œæ¯ä¸ª batch ä¼šå˜å¤§
- å¦‚æœé‡åˆ° OOM (å†…å­˜ä¸è¶³)ï¼Œå¯ä»¥å‡å°‘ batch_size:
  ```python
  # åœ¨ save_best_models_improved.py ç¬¬ 213 è¡Œä¿®æ”¹
  self.batch_size = 72  # æ”¹ä¸º 64 æˆ– 48
  ```

### 4. éªŒè¯é›†è®¾ç½®

- é»˜è®¤ä½¿ç”¨ 20% çš„è®­ç»ƒæ•°æ®ä½œä¸ºéªŒè¯é›†
- å¦‚æœè®­ç»ƒé›†å¤ªå°ï¼Œå¯ä»¥å‡å°‘åˆ° 10%:
  ```bash
  python save_best_models_improved.py --subjects 1 --validate_ratio 0.1
  ```

---

## ğŸ“ æ¯•è®¾ä½¿ç”¨å»ºè®®

### 1. æ€§èƒ½å¯¹æ¯”è¡¨

è®­ç»ƒå®Œæˆåï¼Œåˆ›å»ºå¯¹æ¯”è¡¨:

| é…ç½® | Dataset 2a | æ”¹è¿›ç‚¹ |
|------|-----------|--------|
| åŸºçº¿æ¨¡å‹ | 79.13% | åŸå§‹æ¶æ„ |
| Issue #40 æ”¹è¿› | ~84-87% | ç®€åŒ–FC + 3xå¢å¼º + éªŒè¯é›† |
| **æå‡** | **+5-8%** | |

### 2. æ¼”ç¤ºå»ºè®®

- ä½¿ç”¨ Subject 3 çš„æ”¹è¿›æ¨¡å‹ (é¢„æœŸ ~97%)
- å±•ç¤ºéªŒè¯é›† vs æµ‹è¯•é›†çš„æ€§èƒ½æ›²çº¿
- è¯´æ˜æ”¹è¿›çš„ç§‘å­¦ä¾æ®

### 3. è®ºæ–‡/æŠ¥å‘Š

å¯ä»¥å¼•ç”¨:
- **åŸå§‹è®ºæ–‡**: Song et al. (2023) "EEG Conformer"
- **æ”¹è¿›æ¥æº**: GitHub Issue #40 by snailpt
- **æ”¹è¿›æ•ˆæœ**: å‡†ç¡®ç‡ä» 79.13% æå‡åˆ° 84-87%

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•æŸ¥çœ‹è®­ç»ƒè¿›åº¦?

A: è®­ç»ƒè¿‡ç¨‹ä¼šå®æ—¶æ‰“å°:
```
Epoch: 0   Train loss: 1.386294   Val loss: 1.386294   Test loss: 1.386294
           Train acc: 0.2500   Val acc: 0.2500   Test acc: 0.2500
```

### Q2: å¦‚ä½•æ¢å¤ä¸­æ–­çš„è®­ç»ƒ?

A: å½“å‰è„šæœ¬ä¸æ”¯æŒè‡ªåŠ¨æ¢å¤ï¼Œä½†æ¨¡å‹å·²ä¿å­˜æœ€ä½³ç‰ˆæœ¬ã€‚å¦‚æœä¸­æ–­ï¼Œå¯ä»¥:
1. æ£€æŸ¥ `./models_improved/subject_X_best.pth` æ˜¯å¦å­˜åœ¨
2. å¦‚æœå­˜åœ¨ï¼Œè¯´æ˜å·²ç»æœ‰æœ€ä½³æ¨¡å‹
3. å¦‚æœæƒ³ç»§ç»­è®­ç»ƒï¼Œéœ€è¦ä¿®æ”¹ä»£ç åŠ è½½æ£€æŸ¥ç‚¹

### Q3: å¦‚ä½•å¯¹æ¯”åŸºçº¿å’Œæ”¹è¿›æ¨¡å‹?

A: è®­ç»ƒå®Œæˆå:
```python
# è¯»å–åŸºçº¿æ¨¡å‹ç»Ÿè®¡
import json
with open('./models/subject_3_stats.json') as f:
    baseline = json.load(f)

# è¯»å–æ”¹è¿›æ¨¡å‹ç»Ÿè®¡
with open('./models_improved/subject_3_stats.json') as f:
    improved = json.load(f)

print(f"åŸºçº¿: {baseline['best_accuracy']:.4f}")
print(f"æ”¹è¿›: {improved['best_test_accuracy']:.4f}")
print(f"æå‡: {improved['best_test_accuracy'] - baseline['best_accuracy']:.4f}")
```

### Q4: å¦‚ä½•ä½¿ç”¨ä¿å­˜çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹?

A: å¯ä»¥ä¿®æ”¹ `predict.py` æˆ– `realtime_predict.py`:
```python
# åŠ è½½æ”¹è¿›æ¨¡å‹
checkpoint = torch.load('./models_improved/subject_3_best.pth')
model.load_state_dict(checkpoint['model_state_dict'])
mean = checkpoint['normalization_params']['mean']
std = checkpoint['normalization_params']['std']
```

---

## ğŸ“ å‚è€ƒèµ„æº

- **åŸå§‹ä»“åº“**: https://github.com/eeyhsong/EEG-Conformer
- **Issue #40**: https://github.com/eeyhsong/EEG-Conformer/issues/40
- **é¡¹ç›®äº¤æ¥æŒ‡å—**: `PROJECT_HANDOVER_GUIDE.md`
- **ä½¿ç”¨æŒ‡å—**: `USAGE_GUIDE.md`

---

## âœ… æ£€æŸ¥æ¸…å•

åœ¨ PC ä¸Šè¿è¡Œå‰ï¼Œç¡®ä¿:

- [ ] conda ç¯å¢ƒå·²æ¿€æ´» (`conda activate eeg-moabb`)
- [ ] æ•°æ®å·²ä¸‹è½½ (`./data/2a/A0*T.mat` å’Œ `A0*E.mat` å­˜åœ¨)
- [ ] GPU å¯ç”¨ (`nvidia-smi` æ£€æŸ¥)
- [ ] ç£ç›˜ç©ºé—´å……è¶³ (è‡³å°‘ 5GB ç”¨äºä¿å­˜æ¨¡å‹)
- [ ] å·²åˆ›å»º results ç›®å½• (`mkdir -p results`)

---

**ç¥è®­ç»ƒé¡ºåˆ©ï¼é¢„æœŸæ”¹è¿›æ¨¡å‹ä¼šæœ‰æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼** ğŸš€

å¦‚æœé‡åˆ°é—®é¢˜ï¼Œæ£€æŸ¥:
1. è®­ç»ƒæ—¥å¿—: `./models_improved/log_subject*.txt`
2. ç»Ÿè®¡æ–‡ä»¶: `./models_improved/subject_*_stats.json`
3. æ€»ç»“æ–‡ä»¶: `./models_improved/training_summary.txt`